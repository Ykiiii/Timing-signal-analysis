{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close    Volume   label\n",
      "Date                                                                \n",
      "2023-12-29  139.6300  140.3600  138.7800  139.6900  18733017  131.94\n",
      "2023-12-28  140.7800  141.1400  139.7500  140.2300  16045712  132.57\n",
      "2023-12-27  141.5900  142.0800  139.8860  140.3700  19628618  132.52\n",
      "2023-12-26  141.5900  142.6800  141.1900  141.5200  16780333  133.29\n",
      "2023-12-22  140.7700  141.9900  140.7100  141.4900  26532199  134.99\n",
      "...              ...       ...       ...       ...       ...     ...\n",
      "2020-01-08   69.7410   70.5925   69.6315   70.2520  35325480     NaN\n",
      "2020-01-07   70.0230   70.1750   69.5780   69.7555  34529120     NaN\n",
      "2020-01-06   67.5815   69.9160   67.5500   69.8905  46786860     NaN\n",
      "2020-01-03   67.4000   68.6875   67.3660   68.0760  23412580     NaN\n",
      "2020-01-02   67.4205   68.4340   67.3245   68.4340  27285300     NaN\n",
      "\n",
      "[1006 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "start = datetime.datetime(2020, 1, 1)\n",
    "end = datetime.datetime(2024, 1, 1)\n",
    "df = web.DataReader('GOOGL', 'stooq', start, end)\n",
    "df.dropna(inplace=True)\n",
    "per_days = 10\n",
    "df['label'] = df['Close'].shift(-per_days)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化\n",
    "fit_transform方法首先计算选定列的均值和标准差（即拟合数据），然后将数据转换（缩放）为均值为0，标准差为1的分布。转换后的数据被赋值给变量X。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.26518345  1.23787354  1.28886469  1.2676006  -1.05082779]\n",
      " [ 1.31089744  1.26874918  1.32770914  1.28911254 -1.22989906]\n",
      " [ 1.34309598  1.30595829  1.33315537  1.29468971 -0.99114851]\n",
      " ...\n",
      " [-1.59883732 -1.55059286 -1.56359964 -1.51299633  0.81856825]\n",
      " [-1.60605218 -1.599222   -1.57096807 -1.58528042 -0.7390004 ]\n",
      " [-1.60523727 -1.60925658 -1.57262997 -1.5710188  -0.48093781]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "sca_X = scaler.fit_transform(df.iloc[:,:-1])\n",
    "print(sca_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "mem_his_days = 5\n",
    "from collections import deque\n",
    "deq = deque(maxlen=mem_his_days)\n",
    "\n",
    "X = []\n",
    "for i in sca_X:\n",
    "    deq.append(list(i))\n",
    "    if len(deq)==mem_his_days:\n",
    "        X.append(list(deq))\n",
    "\n",
    "X_lately = X[-per_days:]\n",
    "X = X[:-per_days]\n",
    "print(len(X))\n",
    "print(len(X_lately))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992\n"
     ]
    }
   ],
   "source": [
    "y = df['label'].values[mem_his_days-1:-per_days]\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992, 5, 5)\n",
      "(992,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 5, 10)             640       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 5, 10)             0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 5, 10)             840       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 5, 10)             0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,441\n",
      "Trainable params: 2,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
    "model = Sequential()\n",
    "model.add(LSTM(10,input_shape=X.shape[1:],activation='relu',return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(10,activation='relu',return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(10,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "28/28 [==============================] - 3s 26ms/step - loss: 12371.6114 - mape: 99.9801 - val_loss: 12017.4922 - val_mape: 99.8659\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 11952.2532 - mape: 99.8045 - val_loss: 11937.9873 - val_mape: 99.5255\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 12100.7769 - mape: 99.2190 - val_loss: 10925.9453 - val_mape: 95.8807\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 9428.2840 - mape: 88.3875 - val_loss: 3989.6440 - val_mape: 51.6581\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4652.2535 - mape: 56.2189 - val_loss: 2348.4819 - val_mape: 38.4798\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2728.4467 - mape: 42.3771 - val_loss: 998.2463 - val_mape: 25.2516\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1565.9279 - mape: 30.8206 - val_loss: 492.4598 - val_mape: 17.3527\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1076.5229 - mape: 24.7818 - val_loss: 325.9363 - val_mape: 13.9605\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 824.9385 - mape: 21.3926 - val_loss: 235.7711 - val_mape: 11.2418\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 732.3188 - mape: 20.7038 - val_loss: 202.5415 - val_mape: 10.9043\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 741.8312 - mape: 20.1141 - val_loss: 125.1867 - val_mape: 8.5507\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 660.7806 - mape: 19.4185 - val_loss: 103.5294 - val_mape: 7.9378\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 625.7901 - mape: 18.5120 - val_loss: 161.1199 - val_mape: 9.5015\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 663.0391 - mape: 18.8588 - val_loss: 193.0945 - val_mape: 10.4516\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 656.4632 - mape: 18.3745 - val_loss: 71.5369 - val_mape: 6.6907\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 581.7916 - mape: 18.8554 - val_loss: 75.3426 - val_mape: 6.7480\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 600.6685 - mape: 18.2404 - val_loss: 109.3751 - val_mape: 8.0591\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 566.2664 - mape: 17.3810 - val_loss: 68.7069 - val_mape: 6.3610\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 594.1432 - mape: 18.4152 - val_loss: 59.1411 - val_mape: 6.1178\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 616.4882 - mape: 18.1335 - val_loss: 56.5787 - val_mape: 5.8225\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 549.5109 - mape: 17.3705 - val_loss: 81.3195 - val_mape: 6.8912\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 506.5706 - mape: 17.0780 - val_loss: 80.6694 - val_mape: 6.9283\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 541.9519 - mape: 16.5211 - val_loss: 55.5413 - val_mape: 5.9588\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 594.0989 - mape: 18.2404 - val_loss: 92.9493 - val_mape: 7.1144\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 528.3857 - mape: 16.5469 - val_loss: 56.5348 - val_mape: 5.9226\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 540.8349 - mape: 17.5504 - val_loss: 74.9228 - val_mape: 6.4685\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 500.6068 - mape: 16.4552 - val_loss: 58.3156 - val_mape: 5.8012\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 465.1533 - mape: 15.7024 - val_loss: 51.3213 - val_mape: 5.7015\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 545.3715 - mape: 17.4908 - val_loss: 59.8948 - val_mape: 5.8973\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 482.7374 - mape: 15.9968 - val_loss: 88.7979 - val_mape: 6.9536\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 465.5386 - mape: 16.0019 - val_loss: 55.1381 - val_mape: 5.6753\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 515.0635 - mape: 16.2482 - val_loss: 53.2091 - val_mape: 5.5113\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 464.8524 - mape: 15.3529 - val_loss: 66.3499 - val_mape: 6.3331\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 535.2818 - mape: 16.2959 - val_loss: 59.7351 - val_mape: 5.9147\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 473.9119 - mape: 15.6943 - val_loss: 68.5893 - val_mape: 6.2944\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 444.2939 - mape: 15.1779 - val_loss: 53.9019 - val_mape: 5.6926\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 446.0680 - mape: 15.6142 - val_loss: 55.2731 - val_mape: 5.6257\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 442.8540 - mape: 15.7014 - val_loss: 76.7527 - val_mape: 6.5531\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 483.8258 - mape: 16.1996 - val_loss: 48.4086 - val_mape: 5.4126\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 475.9686 - mape: 16.1094 - val_loss: 59.9484 - val_mape: 5.7283\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 404.5173 - mape: 15.0081 - val_loss: 72.1723 - val_mape: 6.6287\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 492.0679 - mape: 16.3939 - val_loss: 66.6401 - val_mape: 6.1648\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 476.7129 - mape: 15.7213 - val_loss: 73.4277 - val_mape: 6.4531\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 466.9859 - mape: 15.9331 - val_loss: 71.1067 - val_mape: 6.3544\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 476.9784 - mape: 15.4354 - val_loss: 59.0163 - val_mape: 6.0042\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 440.4101 - mape: 15.4814 - val_loss: 60.4856 - val_mape: 5.8391\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 414.9832 - mape: 15.2685 - val_loss: 46.9970 - val_mape: 5.2215\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 465.8832 - mape: 16.0334 - val_loss: 51.9335 - val_mape: 5.7644\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 427.7509 - mape: 15.2752 - val_loss: 65.9865 - val_mape: 6.4171\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 441.2823 - mape: 15.8676 - val_loss: 51.9558 - val_mape: 5.5402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1be8ea31160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=['mape'])\n",
    "model.fit(X_train,y_train,batch_size=32,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yk_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
